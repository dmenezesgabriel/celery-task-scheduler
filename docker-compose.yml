version: "3.3"
services:
  scheduler:
    build:
      context: ./services/scheduler
      dockerfile: Dockerfile
    command: python manage.py run -h 0.0.0.0
    volumes:
      - ./services/scheduler/:/usr/src/app/
    ports:
      - 5000:5000
    env_file:
      - ./.env
    depends_on:
      - redis
    links:
      - redis:redis
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"

  redis:
    image: redis:6.0.5-alpine
    volumes:
      - redis_data:/var/lib/redis
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"

  celery_worker:
    build:
      context: ./services/scheduler
      dockerfile: Dockerfile
    env_file:
      - ./.env
    command: celery -A celery_worker.celery worker --loglevel=INFO
    volumes:
      - ./services/scheduler/:/usr/src/app/
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"

  celery-beat:
    build:
      context: ./services/scheduler
      dockerfile: Dockerfile
    env_file:
      - ./.env
    command: celery -A celery_worker.celery beat --loglevel=INFO
    volumes:
      - ./services/scheduler/:/usr/src/app/
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"

  flower:
    build:
      context: ./services/flower
      dockerfile: Dockerfile
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_PORT=9999
    ports:
      - 9999:9999
    logging:
      driver: "json-file"
      options:
        max-size: "1k"
        max-file: "3"

volumes:
  redis_data:
